{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c8e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __Detection.detection_api import DetectionAPI\n",
    "from __Tracking.tracking_api import TrackerAPI\n",
    "from homo_graphy import PlanProjector\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9a575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    track_thresh = 0.5\n",
    "    match_thresh = 0.5\n",
    "    track_buffer = 60\n",
    "    mot20 = False\n",
    "    cpu_workers = 16   # 듀얼 CPU 적극 활용\n",
    "    chunk_sec   = 10.0 # 15~30초 권장\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6846763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /workspace/PretrainedModel_by_JeonYT/vehicle/epoch_54.pth\n",
      "Loads checkpoint by local backend from path: /workspace/PretrainedModel_by_JeonYT/worker/epoch_100.pth\n"
     ]
    }
   ],
   "source": [
    "detector = DetectionAPI()\n",
    "tracker = TrackerAPI(args=args, detector=detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc95921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 도면 + (선택) H 로드\n",
    "plan_path = \"/workspace/assets/25082_homograph_coordinate-plane.jpg\"\n",
    "plan_pts  = [\n",
    "            (3588, 412),    #point1\n",
    "            (3588, 1036),   #point2\n",
    "            (3588, 1657),   #point3\n",
    "            (2225, 412),    #point4\n",
    "            (2225, 1036),   #point5\n",
    "            (2225, 1657),   #point6\n",
    "            (861, 412),     #point7\n",
    "            (861, 1036),    #point8\n",
    "            (861, 1657),    #point9\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3dca26",
   "metadata": {},
   "source": [
    "### Cam#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f307b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mmyolo/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e9e49dea9a41>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m cam1_tracklets = tracker.trackingVideo(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mvideo_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/workspace/datasets/homography_experiment/1030-1100/2025-08-27_10_30_00_cam#1.mp4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/workspace/results/tracking_result1.mp4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrail_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/workspace/__Tracking/tracking_api.py\u001b[0m in \u001b[0;36mtrackingVideo\u001b[0;34m(self, video_path, save_path, trail_len)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \"\"\"\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# 1) detection+tracking 실행 (화면표시는 하지 않음)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# 2) 비디오 입출력 준비\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/__Tracking/tracking_api.py\u001b[0m in \u001b[0;36mtracking\u001b[0;34m(self, video_path, visualize)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# 1) Detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mdets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# 2) Tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/__Detection/detection_api.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image must be a numpy.ndarray (BGR).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# list of dicts( bbox/score/class_id/... )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/__Detection/ensemble_detection/engine/base.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mmerged\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/__Detection/ensemble_detection/engine/base.py\u001b[0m in \u001b[0;36m_detect_all\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_on_right_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mfuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_on_right_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# mmdet 결과 → 공통 스키마(dict)로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/__Detection/ensemble_detection/engine/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_on_right_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mfuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_on_right_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# mmdet 결과 → 공통 스키마(dict)로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/mmyolo/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/mmyolo/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cam1_tracklets = tracker.trackingVideo(\n",
    "    video_path=\"/workspace/datasets/homography_experiment/1030-1100/2025-08-27_10_30_00_cam#1.mp4\",\n",
    "    save_path=\"/workspace/results/tracking_result1.mp4\",\n",
    "    trail_len=100\n",
    ")\n",
    "\n",
    "# 2) 대응점으로 H 추정 (리스트 안에 '튜플' 형태) --> 예시 나중에 바꿔야함\n",
    "projector1 = PlanProjector(cam1_tracklets, trail_len=60, trail_ttl=30, line_thickness=4, point_radius=6)\n",
    "cam1_pts = [\n",
    "    (1390, 521),  #point1\n",
    "    (1618, 552),  #point2\n",
    "    (1784, 578),  #point3\n",
    "    (1112, 564),  #point4\n",
    "    (1434,620),   #point5\n",
    "    (1709,668),   #point6\n",
    "    (481,651),    #point7\n",
    "    (852,809),    #point8\n",
    "    (1393,1007)   #point9\n",
    "    ]\n",
    "H, mask = projector1.fit_homography(cam1_pts, plan_pts, ransac_thresh=3.0)\n",
    "\n",
    "# 4-1) 예시, 한 프레임만 투영(10번 프레임) & 저장\n",
    "projected, canvas = projector1.projection(cam1_tracklets[10], mode=\"bottom-center\", draw=True)\n",
    "cv2.imwrite(\"/workspace/results/plan_proj_frame1.jpg\", canvas)\n",
    "# 4-2) 전체 프레임 미니맵 비디오 저장\n",
    "projector1.save_video(cam1_tracklets, \"/workspace/results/plan_projection1.mp4\", fps=30, mode=\"bottom-center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e523fc4",
   "metadata": {},
   "source": [
    "### Cam#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam2_tracklets = tracker.trackingVideo(\n",
    "    video_path=\"/workspace/datasets/homography_experiment/1030-1100/2025-08-27_10_30_00_cam#2.mp4\",\n",
    "    save_path=\"/workspace/results/tracking_result2.mp4\",\n",
    "    trail_len=100\n",
    ")\n",
    "\n",
    "# 2) 대응점으로 H 추정 (리스트 안에 '튜플' 형태) --> 예시 나중에 바꿔야함\n",
    "projector2 = PlanProjector(cam2_tracklets, trail_len=60, trail_ttl=30, line_thickness=4, point_radius=6)\n",
    "cam3_pts = [\n",
    "    (1020,1027), #point1\n",
    "    (476,898),   #point2\n",
    "    (294,826),   #point3\n",
    "    (1348,790),  #point4\n",
    "    (1017,772),  #point5\n",
    "    (813,753),   #point6\n",
    "    (1437,716),  #point7\n",
    "    (1213,713),  #point8\n",
    "    (1058,707)   #point9\n",
    "    ]\n",
    "H, mask = projector2.fit_homography(cam3_pts, plan_pts, ransac_thresh=3.0)\n",
    "\n",
    "# 4-1) 예시, 한 프레임만 투영(10번 프레임) & 저장\n",
    "projected, canvas = projector2.projection(cam2_tracklets[10], mode=\"bottom-center\", draw=True)\n",
    "cv2.imwrite(\"/workspace/results/plan_proj_frame2.jpg\", canvas)\n",
    "# 4-2) 전체 프레임 미니맵 비디오 저장\n",
    "projector2.save_video(cam2_tracklets, \"/workspace/results/plan_projection2.mp4\", fps=30, mode=\"bottom-center\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707bfb4",
   "metadata": {},
   "source": [
    " ### Cam#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3bb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam3_tracklets = tracker.trackingVideo(\n",
    "    video_path=\"/workspace/mounted_datasets/Hyundai_dataset/aug1/c1/video.mp4\",\n",
    "    save_path=\"/workspace/results/tracking_result3.mp4\",\n",
    "    trail_len=100\n",
    ")\n",
    "\n",
    "# 2) 대응점으로 H 추정 (리스트 안에 '튜플' 형태) --> 예시 나중에 바꿔야함\n",
    "projector3 = PlanProjector(cam3_tracklets, trail_len=60, trail_ttl=30, line_thickness=4, point_radius=6)\n",
    "cam3_pts = [\n",
    "    (140,309),   #point1\n",
    "    (291,315),   #point2\n",
    "    (398,320),   #point3\n",
    "    (213,376),   #point4\n",
    "    (440,377),   #point5\n",
    "    (588,378),   #point6\n",
    "    (467,596),   #point7\n",
    "    (826,521),   #point8\n",
    "    (965,484)    #point9\n",
    "]\n",
    "H, mask = projector3.fit_homography(cam3_pts, plan_pts, ransac_thresh=3.0)\n",
    "\n",
    "# 4-1) 예시, 한 프레임만 투영(10번 프레임) & 저장\n",
    "projected, canvas = projector3.projection(cam3_tracklets[10], mode=\"bottom-center\", draw=True)\n",
    "cv2.imwrite(\"/workspace/results/plan_proj_frame3.jpg\", canvas)\n",
    "# 4-2) 전체 프레임 미니맵 비디오 저장\n",
    "projector3.save_video(cam3_tracklets, \"/workspace/results/plan_projection3.mp4\", fps=30, mode=\"bottom-center\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmyolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
